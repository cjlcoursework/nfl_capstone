{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "## inputs\n",
    "This notebook has three inputs:\n",
    "1. A NFL `scores` dataset having 1 row per game\n",
    "2. Our NFL `gameplay` dataset - having many rows per game - each row is a 'play' in the games\n",
    "3. An NFL `teams` dataset that matches team names to the abbreviation used in the gameplay data  (e.g. Green Bay Packers == GB)\n",
    "\n",
    "The gameplay data does not have a clear final score - it is primarily concerned with the plays themselves - to get the actual score is hit-and-miss.\n",
    "\n",
    "## goal\n",
    "* The goal is to clean and enrich the data so that we can join gameplay data to the actual scores for each game\n",
    "\n",
    "## cleanup\n",
    "* The gameplay data has one or two incorrect dates\n",
    "* The scores data has present-day abbreviations for historical games (e.g. Jacksonville was 'JAC' until 2013, then became 'JAX' - in the scores data it's always 'JAX')\n",
    "* The gameplay data has Jacksonville as 'JAC' all the way to 2016 (should be 2013) - but we are going to leave that for now and conform our scores to that\n",
    "\n",
    "## outputs\n",
    "Join-able versions of:\n",
    "1. A cleaned NFL `scores` dataset having 1 row per game\n",
    "2. A cleaned NFL `gameplay` dataset - having many rows per game - each row is a 'play' in the games\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 01 - Prepare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.1 - imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding modules /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/src\n"
     ]
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "print(\"Adding modules\", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.2 - setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "FILE_TO_CLEAN=\"gameplay_facts_cleaned_01.parquet\"\n",
    "\n",
    "AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET')\n",
    "AWS_S3_PREFIX = os.getenv('AWS_S3_RAW_PREFIX')\n",
    "\n",
    "RAW_DATA_PATH = '../data/raw'\n",
    "INTERIM_DATA_PATH='../data/interim'\n",
    "\n",
    "# inputs\n",
    "GAME_PLAYS=os.path.join(INTERIM_DATA_PATH,FILE_TO_CLEAN)\n",
    "TEAM_SCORES=os.path.join(RAW_DATA_PATH,\"spreadspoke_scores.csv\")\n",
    "TEAM_NAMES=os.path.join(RAW_DATA_PATH,\"nfl_teams.csv\")\n",
    "\n",
    "\n",
    "# output\n",
    "CLEAN_FACTS_DF_NAME=os.path.join(INTERIM_DATA_PATH, \"gameplay_facts_cleaned_02.parquet\")\n",
    "CLEAN_SCORES_DF_NAME=os.path.join(INTERIM_DATA_PATH, \"nfl_scores.parquet\")\n",
    "READ_ME = os.path.join(INTERIM_DATA_PATH,\"README.03-cjl-clean.txt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "from src.data.s3utils import download_from_s3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.3 - check for supporting input files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists:  /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/data/raw/nfl_teams.csv\n",
      "Already exists:  /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/data/raw/spreadspoke_scores.csv\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(\n",
    "    bucket=AWS_S3_BUCKET,\n",
    "    prefix=AWS_S3_PREFIX,\n",
    "    local_dir=os.path.abspath(RAW_DATA_PATH),\n",
    "    wishlist=['spreadspoke_scores.csv', 'nfl_teams.csv']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "if not os.path.exists(GAME_PLAYS):\n",
    "    raise Exception(f\"Can't find the input file {GAME_PLAYS} .  Have you run the preceding notebooks? \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 02 - Get scores data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.1 - load spreadscores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "date                   datetime64[ns]\nseason                          int64\nweek                           object\nschedule_playoff                 bool\nhome_team                      object\nscore_home                      int64\nscore_away                      int64\naway_team                      object\nstadium                        object\nstadium_neutral                  bool\nweather_temperature           float64\nweather_wind_mph              float64\nweather_humidity              float64\ndtype: object"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "scores_df = pd.read_csv(TEAM_SCORES, parse_dates=['schedule_date'])\n",
    "\n",
    "# clean up column names and data that we'll join on later\n",
    "scores_df.drop(columns=['team_favorite_id', 'spread_favorite', 'over_under_line', 'weather_detail'], inplace=True)\n",
    "scores_df['team_away'] = scores_df['team_away'].str.strip()\n",
    "scores_df['team_home'] = scores_df['team_home'].str.strip()\n",
    "scores_df.rename(columns={\n",
    "    'schedule_date': 'date',\n",
    "    'schedule_season': 'season',\n",
    "    'schedule_week': 'week',\n",
    "    'team_home': 'home_team',\n",
    "    'team_away': 'away_team'\n",
    "}, inplace=True)\n",
    "\n",
    "scores_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.2 - load teams list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "team_name    object\nteam_id      object\ndtype: object"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "team_df = pd.read_csv(TEAM_NAMES)\n",
    "\n",
    "# clean up column names and data that we'll join on later\n",
    "team_df['team_name'] = team_df['team_name'].str.strip()\n",
    "team_df['team_id'] = team_df['team_id'].str.strip()\n",
    "team_df.drop(columns=['team_name_short', 'team_id_pfr','team_conference', 'team_conference_pre2002', 'team_division', 'team_division_pre2002'], inplace=True)\n",
    "\n",
    "team_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.3 - merge team_ids into score_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def merge_team_id(scores_df : pd.DataFrame, team_df : pd.DataFrame,  home_or_away_team: str) -> pd.DataFrame:\n",
    "    \"\"\"02.3 - merge team_ids into score_df\n",
    "    The scores_df df has team names as full names, but joining with other data, it should be the abbreviation\n",
    "    Use the teams_df to get the abbreviation into the scores and also validate that the team name is correct\n",
    "\n",
    "    :param team_df: all team names and abbreviations\n",
    "    :param scores_df: spreadspoke scores df\n",
    "    :param home_or_away_team: literally home_team or away_team\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    id_name = home_or_away_team.strip() + \"_id\"\n",
    "    # perform the merge\n",
    "    df2 = scores_df.merge(team_df, left_on=home_or_away_team, right_on='team_name', how='left', indicator=True)\n",
    "\n",
    "    # Jacksonville was JAC prior to 2013, but this dataset thinks it was mid 2016 - use 2016\n",
    "    df2.loc[(df2.season < 2016) & (df2['team_id'] == 'JAX'), 'team_id'] = 'JAC'\n",
    "\n",
    "    # the dataset stores team abbreviations, not names, so label them clearly as such\n",
    "    df2.rename(columns={'team_id': id_name}, inplace=True)\n",
    "\n",
    "    # quick validation\n",
    "    cf = df2.loc[( df2[home_or_away_team] != df2.team_name), [home_or_away_team]].sum().item()\n",
    "    assert cf == 0\n",
    "\n",
    "    # ok, now drop the columns we no longer need and pass the merged scores_df df back\n",
    "    df2.drop(columns=['_merge', 'team_name'], inplace=True)\n",
    "    return df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add the team abbreviation to the scores data:  scores now has a home_team_id (abbreviation)\n"
     ]
    },
    {
     "data": {
      "text/plain": "            home_team home_team_id\n0      Miami Dolphins          MIA\n1      Houston Oilers          TEN\n2  San Diego Chargers           SD\n3      Miami Dolphins          MIA\n4   Green Bay Packers           GB",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home_team</th>\n      <th>home_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miami Dolphins</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Houston Oilers</td>\n      <td>TEN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>San Diego Chargers</td>\n      <td>SD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Miami Dolphins</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Green Bay Packers</td>\n      <td>GB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"add the team abbreviation to the scores data:  scores now has a home_team_id (abbreviation)\")\n",
    "scores_df = merge_team_id(scores_df=scores_df, team_df=team_df, home_or_away_team='home_team')\n",
    "scores_df[['home_team', 'home_team_id']].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores now has a away_team_id (abbreviation)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         away_team away_team_id\n0  Oakland Raiders          OAK\n1   Denver Broncos          DEN\n2    Buffalo Bills          BUF\n3    New York Jets          NYJ\n4  Baltimore Colts          IND",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>away_team</th>\n      <th>away_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oakland Raiders</td>\n      <td>OAK</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Denver Broncos</td>\n      <td>DEN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buffalo Bills</td>\n      <td>BUF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New York Jets</td>\n      <td>NYJ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Baltimore Colts</td>\n      <td>IND</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"scores now has a away_team_id (abbreviation)\")\n",
    "scores_df = merge_team_id(scores_df=scores_df, team_df=team_df, home_or_away_team='away_team')\n",
    "scores_df[['away_team', 'away_team_id']].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# validate that there are no null team abbreviations (id's)\n",
    "assert 0 == scores_df.loc[(scores_df.home_team_id.isna())].count().sum()\n",
    "assert 0 == scores_df.loc[(scores_df.away_team_id.isna())].count().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 03 - get gameplay data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "play_id                 float32\ngame_id                  object\nold_game_id              object\nhome_team                object\naway_team                object\n                         ...   \nspecial                 float32\nplay                    float32\nout_of_bounds           float32\nhome_opening_kickoff    float32\nadmin_event               int64\nLength: 156, dtype: object"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the actual play by play data\n",
    "gameplay_df = pd.read_parquet(GAME_PLAYS)\n",
    "gameplay_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 04 - conform score and gameplay data for joins\n",
    "Look at the Detroit Lions 2017 season - both datasets should have 16 games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 03.1 - check gameplay dataset Detroit Lions season"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "s = pd.Series(gameplay_df.season).unique().tolist()\n",
    "validate_year = s[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: [(2019, 2019-09-08, 2019_01_DET_ARI, ARI, DET), (2019, 2019-09-15, 2019_02_LAC_DET, DET, LAC), (2019, 2019-09-22, 2019_03_DET_PHI, PHI, DET), (2019, 2019-09-29, 2019_04_KC_DET, DET, KC), (2019, 2019-10-14, 2019_06_DET_GB, GB, DET), (2019, 2019-10-20, 2019_07_MIN_DET, DET, MIN), (2019, 2019-10-27, 2019_08_NYG_DET, DET, NYG), (2019, 2019-11-03, 2019_09_DET_OAK, LV, DET), (2019, 2019-11-10, 2019_10_DET_CHI, CHI, DET), (2019, 2019-11-17, 2019_11_DAL_DET, DET, DAL), (2019, 2019-11-24, 2019_12_DET_WAS, WAS, DET), (2019, 2019-11-28, 2019_13_CHI_DET, DET, CHI), (2019, 2019-12-08, 2019_14_DET_MIN, MIN, DET), (2019, 2019-12-15, 2019_15_TB_DET, DET, TB), (2019, 2019-12-22, 2019_16_DET_DEN, DEN, DET), (2019, 2019-12-29, 2019_17_GB_DET, DET, GB)]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>season</th>\n      <th>game_date</th>\n      <th>game_id</th>\n      <th>home_team</th>\n      <th>away_team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">2019</th>\n      <th>2019-09-08</th>\n      <th>2019_01_DET_ARI</th>\n      <th>ARI</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-09-15</th>\n      <th>2019_02_LAC_DET</th>\n      <th>DET</th>\n      <th>LAC</th>\n    </tr>\n    <tr>\n      <th>2019-09-22</th>\n      <th>2019_03_DET_PHI</th>\n      <th>PHI</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-09-29</th>\n      <th>2019_04_KC_DET</th>\n      <th>DET</th>\n      <th>KC</th>\n    </tr>\n    <tr>\n      <th>2019-10-14</th>\n      <th>2019_06_DET_GB</th>\n      <th>GB</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-10-20</th>\n      <th>2019_07_MIN_DET</th>\n      <th>DET</th>\n      <th>MIN</th>\n    </tr>\n    <tr>\n      <th>2019-10-27</th>\n      <th>2019_08_NYG_DET</th>\n      <th>DET</th>\n      <th>NYG</th>\n    </tr>\n    <tr>\n      <th>2019-11-03</th>\n      <th>2019_09_DET_OAK</th>\n      <th>LV</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-11-10</th>\n      <th>2019_10_DET_CHI</th>\n      <th>CHI</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-11-17</th>\n      <th>2019_11_DAL_DET</th>\n      <th>DET</th>\n      <th>DAL</th>\n    </tr>\n    <tr>\n      <th>2019-11-24</th>\n      <th>2019_12_DET_WAS</th>\n      <th>WAS</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-11-28</th>\n      <th>2019_13_CHI_DET</th>\n      <th>DET</th>\n      <th>CHI</th>\n    </tr>\n    <tr>\n      <th>2019-12-08</th>\n      <th>2019_14_DET_MIN</th>\n      <th>MIN</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-12-15</th>\n      <th>2019_15_TB_DET</th>\n      <th>DET</th>\n      <th>TB</th>\n    </tr>\n    <tr>\n      <th>2019-12-22</th>\n      <th>2019_16_DET_DEN</th>\n      <th>DEN</th>\n      <th>DET</th>\n    </tr>\n    <tr>\n      <th>2019-12-29</th>\n      <th>2019_17_GB_DET</th>\n      <th>DET</th>\n      <th>GB</th>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_columns = ['season', 'game_date', 'game_id','home_team', 'away_team']\n",
    "gameplay_df.loc[(gameplay_df.season == validate_year) & ((gameplay_df.home_team=='DET') | (gameplay_df.away_team=='DET')) , check_columns].groupby(check_columns).count().sort_values(by='game_date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 03.2 - check scores dataset 2017 Detroit Lions season"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "       season       date home_team_id away_team_id\n12412    2019 2019-09-08          ARI          DET\n12432    2019 2019-09-15          DET          LAC\n12454    2019 2019-09-22          PHI          DET\n12466    2019 2019-09-29          DET           KC\n12502    2019 2019-10-14           GB          DET\n12509    2019 2019-10-20          DET          MIN\n12521    2019 2019-10-27          DET          NYG\n12541    2019 2019-11-03          OAK          DET\n12547    2019 2019-11-10          CHI          DET\n12562    2019 2019-11-17          DET          DAL\n12585    2019 2019-11-24          WAS          DET\n12589    2019 2019-11-28          DET          CHI\n12612    2019 2019-12-08          MIN          DET\n12624    2019 2019-12-15          DET           TB\n12641    2019 2019-12-22          DEN          DET\n12657    2019 2019-12-29          DET           GB",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>date</th>\n      <th>home_team_id</th>\n      <th>away_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12412</th>\n      <td>2019</td>\n      <td>2019-09-08</td>\n      <td>ARI</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12432</th>\n      <td>2019</td>\n      <td>2019-09-15</td>\n      <td>DET</td>\n      <td>LAC</td>\n    </tr>\n    <tr>\n      <th>12454</th>\n      <td>2019</td>\n      <td>2019-09-22</td>\n      <td>PHI</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12466</th>\n      <td>2019</td>\n      <td>2019-09-29</td>\n      <td>DET</td>\n      <td>KC</td>\n    </tr>\n    <tr>\n      <th>12502</th>\n      <td>2019</td>\n      <td>2019-10-14</td>\n      <td>GB</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12509</th>\n      <td>2019</td>\n      <td>2019-10-20</td>\n      <td>DET</td>\n      <td>MIN</td>\n    </tr>\n    <tr>\n      <th>12521</th>\n      <td>2019</td>\n      <td>2019-10-27</td>\n      <td>DET</td>\n      <td>NYG</td>\n    </tr>\n    <tr>\n      <th>12541</th>\n      <td>2019</td>\n      <td>2019-11-03</td>\n      <td>OAK</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12547</th>\n      <td>2019</td>\n      <td>2019-11-10</td>\n      <td>CHI</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12562</th>\n      <td>2019</td>\n      <td>2019-11-17</td>\n      <td>DET</td>\n      <td>DAL</td>\n    </tr>\n    <tr>\n      <th>12585</th>\n      <td>2019</td>\n      <td>2019-11-24</td>\n      <td>WAS</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12589</th>\n      <td>2019</td>\n      <td>2019-11-28</td>\n      <td>DET</td>\n      <td>CHI</td>\n    </tr>\n    <tr>\n      <th>12612</th>\n      <td>2019</td>\n      <td>2019-12-08</td>\n      <td>MIN</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12624</th>\n      <td>2019</td>\n      <td>2019-12-15</td>\n      <td>DET</td>\n      <td>TB</td>\n    </tr>\n    <tr>\n      <th>12641</th>\n      <td>2019</td>\n      <td>2019-12-22</td>\n      <td>DEN</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>12657</th>\n      <td>2019</td>\n      <td>2019-12-29</td>\n      <td>DET</td>\n      <td>GB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_columns = ['season', 'date', 'home_team_id', 'away_team_id']\n",
    "scores_df.loc[(scores_df.season==validate_year ) & ((scores_df.home_team=='Detroit Lions') | (scores_df.away_team=='Detroit Lions')), check_columns].sort_values(by='date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "gameplay_df.home_team = gameplay_df.home_team.str.strip()\n",
    "gameplay_df.away_team = gameplay_df.away_team.str.strip()\n",
    "gameplay_df.game_id = gameplay_df.game_id.str.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "index\n1        ATL\n2        ATL\n3        ATL\n4        ATL\n5        ATL\n        ... \n48025    SF_\n48026    SF_\n48028    SF_\n48030    SF_\n48032    SF_\nName: game_id, Length: 43976, dtype: object"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameplay_df.game_id.str[8:11]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "gameplay_df.loc[ (gameplay_df.away_team == 'LV') &  (gameplay_df.game_id.str[8:11] == 'OAK'), 'away_team'] = 'OAK'\n",
    "gameplay_df.loc[ (gameplay_df.home_team == 'LV') &  (gameplay_df.game_id.str[-3:] == 'OAK'), 'home_team'] = 'OAK'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "# the gameplay data date is still an object, and that's good for concatenating later, but we also want a real date\n",
    "gameplay_df['date_string'] = gameplay_df['game_date']\n",
    "gameplay_df['game_date'] = pd.to_datetime(gameplay_df['game_date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "gameplay_df['game_id']  = gameplay_df['date_string'].astype('string').str.replace(\"-\",\"\")+gameplay_df.home_team.str.lower() + gameplay_df.away_team.str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "scores_df['game_id'] = scores_df['date'].astype('string').str.replace(\"-\",\"\")+scores_df.home_team_id.str.lower() + scores_df.away_team_id.str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# try a test merge\n",
    "test_df = gameplay_df.merge(scores_df, left_on='game_id', right_on='game_id', how='left', indicator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo - we have a complete join etween scores and gameplay\n"
     ]
    }
   ],
   "source": [
    "if 0 == test_df.loc[(test_df['_merge'] != 'both')].count().sum():\n",
    "    print(\"Yahoo - we have a complete join between scores and gameplay\")\n",
    "else:\n",
    "    raise Exception(\"still not a complete join - needs more work!!!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 03.3 - conform game_ids as the join key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 03.4 - test the join - iterate and clean until it's 100%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "# one more redundant validate on the merge\n",
    "assert test_df.loc[test_df._merge == 'left_only'].size == 0\n",
    "assert test_df.loc[test_df._merge == 'right_only'].size == 0\n",
    "assert 0 == test_df.loc[(test_df['_merge'] != 'both')].count().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 05 - output gameplay and score data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "gameplay_df.to_parquet(CLEAN_FACTS_DF_NAME, engine='fastparquet',  compression='snappy')\n",
    "scores_df.to_parquet(CLEAN_SCORES_DF_NAME, engine='fastparquet',  compression='snappy')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing readme to local path: ../data/interim/README.03-cjl-clean.txt\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(READ_ME):\n",
    "    print(\"Writing readme to local path:\",READ_ME)\n",
    "\n",
    "    pd.DataFrame([\n",
    "        {'file': {os.path.basename(CLEAN_FACTS_DF_NAME)}, 'desc': 'clean version of gameplay with just the core facts'},\n",
    "        {'file': {os.path.basename(CLEAN_SCORES_DF_NAME)}, 'desc': 'less-clean version of gameplay dimensions that are only non-null for specific kinds of facts'}]).to_csv(READ_ME, index=False)\n",
    "else:\n",
    "    print(READ_ME, \" already exists\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
