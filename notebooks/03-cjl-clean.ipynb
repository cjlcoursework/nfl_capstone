{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "## inputs\n",
    "This notebook has three inputs:\n",
    "1. A NFL `scores` dataset having 1 row per game\n",
    "2. Our NFL `gameplay` dataset - having many rows per game - each row is a 'play' in the games\n",
    "3. An NFL `teams` dataset that matches team names to the abbreviation used in the gameplay data  (e.g. Green Bay Packers == GB)\n",
    "\n",
    "The gameplay data does not have a clear final score - it is primarily concerned with the plays themselves - to get the actual score is hit-and-miss.\n",
    "\n",
    "## goal\n",
    "* The goal is to clean and enrich the data so that we can join gameplay data to the actual scores for each game\n",
    "\n",
    "## cleanup\n",
    "* The gameplay data has one or two incorrect dates\n",
    "* The scores data has present-day abbreviations for historical games (e.g. Jacksonville was 'JAC' until 2013, then became 'JAX' - in the scores data it's always 'JAX')\n",
    "* The gameplay data has Jacksonville as 'JAC' all the way to 2016 (should be 2013) - but we are going to leave that for now and conform our scores to that\n",
    "\n",
    "## outputs\n",
    "Join-able versions of:\n",
    "1. A cleaned NFL `scores` dataset having 1 row per game\n",
    "2. A cleaned NFL `gameplay` dataset - having many rows per game - each row is a 'play' in the games\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 01 - Prepare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.1 - imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding modules /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/src\n"
     ]
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "print(\"Adding modules\", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.2 - setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "FILE_TO_CLEAN=\"gameplay_facts_cleaned_01.parquet\"\n",
    "\n",
    "AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET')\n",
    "AWS_S3_PREFIX = os.getenv('AWS_S3_RAW_PREFIX')\n",
    "\n",
    "RAW_DATA_PATH = '../data/raw'\n",
    "INTERIM_DATA_PATH='../data/interim'\n",
    "\n",
    "# inputs\n",
    "GAME_PLAYS=os.path.join(INTERIM_DATA_PATH,FILE_TO_CLEAN)\n",
    "TEAM_SCORES=os.path.join(RAW_DATA_PATH,\"spreadspoke_scores.csv\")\n",
    "TEAM_NAMES=os.path.join(RAW_DATA_PATH,\"nfl_teams.csv\")\n",
    "\n",
    "\n",
    "# output\n",
    "CLEAN_FACTS_DF_NAME=os.path.join(INTERIM_DATA_PATH, \"gameplay_facts_cleaned_02.parquet\")\n",
    "CLEAN_SCORES_DF_NAME=os.path.join(INTERIM_DATA_PATH, \"nfl_scores.parquet\")\n",
    "READ_ME = os.path.join(INTERIM_DATA_PATH,\"README.03-cjl-clean.txt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "from src.data.s3utils import download_from_s3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 01.3 - check for supporting input files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists:  /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/data/raw/nfl_teams.csv\n",
      "Already exists:  /Users/christopherlomeli/Source/courses/datascience/nfl_capstone/data/raw/spreadspoke_scores.csv\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(\n",
    "    bucket=AWS_S3_BUCKET,\n",
    "    prefix=AWS_S3_PREFIX,\n",
    "    local_dir=os.path.abspath(RAW_DATA_PATH),\n",
    "    wishlist=['spreadspoke_scores.csv', 'nfl_teams.csv']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "if not os.path.exists(GAME_PLAYS):\n",
    "    raise Exception(f\"Can't find the input file {GAME_PLAYS} .  Have you run the preceding notebooks? \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 02 - Get scores data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.1 - load spreadscores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "date                   datetime64[ns]\nseason                          int64\nweek                           object\nschedule_playoff                 bool\nhome_team                      object\nscore_home                      int64\nscore_away                      int64\naway_team                      object\nstadium                        object\nstadium_neutral                  bool\nweather_temperature           float64\nweather_wind_mph              float64\nweather_humidity              float64\ndtype: object"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "scores_df = pd.read_csv(TEAM_SCORES, parse_dates=['schedule_date'])\n",
    "\n",
    "# clean up column names and data that we'll join on later\n",
    "scores_df.drop(columns=['team_favorite_id', 'spread_favorite', 'over_under_line', 'weather_detail'], inplace=True)\n",
    "scores_df['team_away'] = scores_df['team_away'].str.strip()\n",
    "scores_df['team_home'] = scores_df['team_home'].str.strip()\n",
    "scores_df.rename(columns={\n",
    "    'schedule_date': 'date',\n",
    "    'schedule_season': 'season',\n",
    "    'schedule_week': 'week',\n",
    "    'team_home': 'home_team',\n",
    "    'team_away': 'away_team'\n",
    "}, inplace=True)\n",
    "\n",
    "scores_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.2 - load teams list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "team_name    object\nteam_id      object\ndtype: object"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "team_df = pd.read_csv(TEAM_NAMES)\n",
    "\n",
    "# clean up column names and data that we'll join on later\n",
    "team_df['team_name'] = team_df['team_name'].str.strip()\n",
    "team_df['team_id'] = team_df['team_id'].str.strip()\n",
    "team_df.drop(columns=['team_name_short', 'team_id_pfr','team_conference', 'team_conference_pre2002', 'team_division', 'team_division_pre2002'], inplace=True)\n",
    "\n",
    "team_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.3 - merge team_ids into score_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def merge_team_id(scores_df : pd.DataFrame, team_df : pd.DataFrame,  home_or_away_team: str) -> pd.DataFrame:\n",
    "    \"\"\"02.3 - merge team_ids into score_df\n",
    "    The scores_df df has team names as full names, but joining with other data, it should be the abbreviation\n",
    "    Use the teams_df to get the abbreviation into the scores and also validate that the team name is correct\n",
    "\n",
    "    :param team_df: all team names and abbreviations\n",
    "    :param scores_df: spreadspoke scores df\n",
    "    :param home_or_away_team: literally home_team or away_team\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    id_name = home_or_away_team.strip() + \"_id\"\n",
    "    # perform the merge\n",
    "    df2 = scores_df.merge(team_df, left_on=home_or_away_team, right_on='team_name', how='left', indicator=True)\n",
    "\n",
    "    # Jacksonville was JAC prior to 2013, but this dataset thinks it was mid 2016 - use 2016\n",
    "    df2.loc[(df2.season < 2016) & (df2['team_id'] == 'JAX'), 'team_id'] = 'JAC'\n",
    "\n",
    "    # the dataset stores team abbreviations, not names, so label them clearly as such\n",
    "    df2.rename(columns={'team_id': id_name}, inplace=True)\n",
    "\n",
    "    # quick validation\n",
    "    cf = df2.loc[( df2[home_or_away_team] != df2.team_name), [home_or_away_team]].sum().item()\n",
    "    assert cf == 0\n",
    "\n",
    "    # ok, now drop the columns we no longer need and pass the merged scores_df df back\n",
    "    df2.drop(columns=['_merge', 'team_name'], inplace=True)\n",
    "    return df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add the team abbreviation to the scores data:  scores now has a home_team_id (abbreviation)\n"
     ]
    },
    {
     "data": {
      "text/plain": "            home_team home_team_id\n0      Miami Dolphins          MIA\n1      Houston Oilers          TEN\n2  San Diego Chargers           SD\n3      Miami Dolphins          MIA\n4   Green Bay Packers           GB",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home_team</th>\n      <th>home_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miami Dolphins</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Houston Oilers</td>\n      <td>TEN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>San Diego Chargers</td>\n      <td>SD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Miami Dolphins</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Green Bay Packers</td>\n      <td>GB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"add the team abbreviation to the scores data:  scores now has a home_team_id (abbreviation)\")\n",
    "scores_df = merge_team_id(scores_df=scores_df, team_df=team_df, home_or_away_team='home_team')\n",
    "scores_df[['home_team', 'home_team_id']].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores now has a away_team_id (abbreviation)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         away_team away_team_id\n0  Oakland Raiders          OAK\n1   Denver Broncos          DEN\n2    Buffalo Bills          BUF\n3    New York Jets          NYJ\n4  Baltimore Colts          IND",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>away_team</th>\n      <th>away_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oakland Raiders</td>\n      <td>OAK</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Denver Broncos</td>\n      <td>DEN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buffalo Bills</td>\n      <td>BUF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New York Jets</td>\n      <td>NYJ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Baltimore Colts</td>\n      <td>IND</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"scores now has a away_team_id (abbreviation)\")\n",
    "scores_df = merge_team_id(scores_df=scores_df, team_df=team_df, home_or_away_team='away_team')\n",
    "scores_df[['away_team', 'away_team_id']].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# validate that there are no null team abbreviations (id's)\n",
    "assert 0 == scores_df.loc[(scores_df.home_team_id.isna())].count().sum()\n",
    "assert 0 == scores_df.loc[(scores_df.away_team_id.isna())].count().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 02.4 - get gameplay data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "play_id                 float32\ngame_id                  object\nold_game_id              object\nhome_team                object\naway_team                object\n                         ...   \nspecial                 float32\nplay                    float32\nout_of_bounds           float32\nhome_opening_kickoff    float32\nadmin_event               int64\nLength: 156, dtype: object"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the actual play by play data\n",
    "gameplay_df = pd.read_parquet(GAME_PLAYS)\n",
    "gameplay_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 03 - conform score and gameplay data for joins\n",
    "Whether we end up joining or not, we still want to use this to cross-check the gameplay data against the scores data\n",
    "Look at the Detroit Lions 2017 season - both datasets should have 16 games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 03.1 - check gameplay dataset Detroit Lions season"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "# grab the first season we find - we'll use it to match the two datasets\n",
    "s = pd.Series(gameplay_df.season).unique().tolist()\n",
    "validate_year = s[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 03.2 - check that the scores_df and gameplay_df match for a random team in a season\n",
    "todo - automate this validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "check_columns = ['season', 'game_date', 'game_id','home_team', 'away_team']\n",
    "gdf = gameplay_df.loc[\n",
    "    (gameplay_df.season == validate_year) & ((gameplay_df.home_team=='DET') | (gameplay_df.away_team=='DET')) , check_columns]\\\n",
    "    .groupby(check_columns).count().sort_values(by='game_date').reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "check_columns = ['season', 'date', 'home_team_id', 'away_team_id']\n",
    "sdf = scores_df.loc[(scores_df.season==validate_year ) & ((scores_df.home_team=='Detroit Lions') | (scores_df.away_team=='Detroit Lions')), check_columns].sort_values(by='date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# basic check for same size\n",
    "assert sdf.shape[0] == gdf.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking date against game_date :: OK\n",
      "Checking home_team_id against home_team :: OK\n",
      "Checking away_team_id against away_team :: OK\n"
     ]
    }
   ],
   "source": [
    "# check that each set has the same values\n",
    "def compare_col(sdf, scolumn, gdf, gcolumn):\n",
    "    s = set(sdf[scolumn])\n",
    "    g = set(gdf[gcolumn])\n",
    "    print(f\"Checking {scolumn} against {gcolumn} ::\", end=\" \")\n",
    "    assert s.difference(g) == set()\n",
    "    print(\"OK\")\n",
    "\n",
    "compare_col(sdf, 'date', gdf, 'game_date')\n",
    "compare_col(sdf, 'home_team_id', gdf, 'home_team')\n",
    "compare_col(sdf, 'away_team_id', gdf, 'away_team')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## iterate - check and fix any discrepancies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "gameplay_df.home_team = gameplay_df.home_team.str.strip()\n",
    "gameplay_df.away_team = gameplay_df.away_team.str.strip()\n",
    "gameplay_df.game_id = gameplay_df.game_id.str.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "gameplay_df.loc[ (gameplay_df.away_team == 'LV') &  (gameplay_df.game_id.str[8:11] == 'OAK'), 'away_team'] = 'OAK'\n",
    "gameplay_df.loc[ (gameplay_df.home_team == 'LV') &  (gameplay_df.game_id.str[-3:] == 'OAK'), 'home_team'] = 'OAK'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "# the gameplay data date is still an object, and that's good for concatenating later, but we also want a real date\n",
    "gameplay_df['date_string'] = gameplay_df['game_date']\n",
    "gameplay_df['game_date'] = pd.to_datetime(gameplay_df['game_date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "gameplay_df['game_id']  = gameplay_df['date_string'].astype('string').str.replace(\"-\",\"\")+gameplay_df.home_team.str.lower() + gameplay_df.away_team.str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "scores_df['game_id'] = scores_df['date'].astype('string').str.replace(\"-\",\"\")+scores_df.home_team_id.str.lower() + scores_df.away_team_id.str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 03.4 - test the join - iterate and clean until it's 100%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# try a test merge\n",
    "test_df = gameplay_df.merge(scores_df, left_on='game_id', right_on='game_id', how='left', indicator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo - we have a complete join etween scores and gameplay\n"
     ]
    }
   ],
   "source": [
    "if 0 == test_df.loc[(test_df['_merge'] != 'both')].count().sum():\n",
    "    print(\"Yahoo - we have a complete join between scores and gameplay\")\n",
    "else:\n",
    "    raise Exception(\"still not a complete join - needs more work!!!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 05 - output gameplay and score data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "gameplay_df.to_parquet(CLEAN_FACTS_DF_NAME, engine='fastparquet',  compression='snappy')\n",
    "scores_df.to_parquet(CLEAN_SCORES_DF_NAME, engine='fastparquet',  compression='snappy')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing readme to local path: ../data/interim/README.03-cjl-clean.txt\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(READ_ME):\n",
    "    print(\"Writing readme to local path:\",READ_ME)\n",
    "\n",
    "    pd.DataFrame([\n",
    "        {'file': {os.path.basename(CLEAN_FACTS_DF_NAME)}, 'desc': 'clean version of gameplay with just the core facts'},\n",
    "        {'file': {os.path.basename(CLEAN_SCORES_DF_NAME)}, 'desc': 'less-clean version of gameplay dimensions that are only non-null for specific kinds of facts'}]).to_csv(READ_ME, index=False)\n",
    "else:\n",
    "    print(READ_ME, \" already exists\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
